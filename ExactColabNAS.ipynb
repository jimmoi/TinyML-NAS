{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local ColabNAS - Exact Configuration\n",
    "\n",
    "Using the complete flower dataset with your exact specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from local_colabnas import LocalColabNAS, test_tflite_model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: C:\\Users\\Chakkaphan\\.keras\\datasets\\flower_photos\n",
      "Classes found: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# Download and setup dataset - exact as requested\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
    "data_dir = Path(data_dir).with_suffix('')\n",
    "\n",
    "# Fix dataset structure - point to actual flower_photos folder\n",
    "actual_data_dir = data_dir / 'flower_photos'\n",
    "if actual_data_dir.exists():\n",
    "    data_dir = actual_data_dir\n",
    "\n",
    "print(f\"Dataset directory: {data_dir}\")\n",
    "print(f\"Classes found: {[d.name for d in data_dir.iterdir() if d.is_dir()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Input shape: (50, 50, 3)\n",
      "  RAM limit: 40960 bytes\n",
      "  Flash limit: 131072 bytes\n",
      "  MACC limit: 2730000\n"
     ]
    }
   ],
   "source": [
    "# Exact configuration from your request\n",
    "input_shape = (50,50,3)\n",
    "\n",
    "#target: STM32L412KBU3\n",
    "#273 CoreMark, 40 kiB RAM, 128 kiB Flash\n",
    "peak_RAM_upper_bound = 40960\n",
    "Flash_upper_bound = 131072\n",
    "MACC_upper_bound = 2730000 #CoreMark * 1e4\n",
    "\n",
    "path_to_training_set = data_dir\n",
    "val_split = 0.3\n",
    "cache = True\n",
    "save_path = './trained_models/'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Input shape: {input_shape}\")\n",
    "print(f\"  RAM limit: {peak_RAM_upper_bound} bytes\")\n",
    "print(f\"  Flash limit: {Flash_upper_bound} bytes\")\n",
    "print(f\"  MACC limit: {MACC_upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "\n",
      "ColabNAS initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# GPU check (equivalent to !nvidia-smi)\n",
    "print(\"GPU Information:\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"  {gpu}\")\n",
    "else:\n",
    "    print(\"  No GPU detected - using CPU\")\n",
    "\n",
    "# Initialize ColabNAS (using LocalColabNAS)\n",
    "colabNAS = LocalColabNAS(\n",
    "    max_RAM=peak_RAM_upper_bound, \n",
    "    max_Flash=Flash_upper_bound, \n",
    "    max_MACC=MACC_upper_bound, \n",
    "    path_to_training_set=str(path_to_training_set), \n",
    "    val_split=val_split, \n",
    "    cache=cache, \n",
    "    input_shape=input_shape, \n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "print(\"\\nColabNAS initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/81 [============================>.] - ETA: 0s - loss: 1.3429 - accuracy: 0.3949\n",
      "Epoch 20: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 1.3422 - accuracy: 0.3943 - val_loss: 1.3204 - val_accuracy: 0.4024\n",
      "Epoch 21/99\n",
      "73/81 [==========================>...] - ETA: 0s - loss: 1.3421 - accuracy: 0.3947\n",
      "Epoch 21: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3408 - accuracy: 0.3970 - val_loss: 1.3720 - val_accuracy: 0.3833\n",
      "Epoch 22/99\n",
      "70/81 [========================>.....] - ETA: 0s - loss: 1.3437 - accuracy: 0.3929\n",
      "Epoch 22: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3398 - accuracy: 0.3951 - val_loss: 1.3143 - val_accuracy: 0.4060\n",
      "Epoch 23/99\n",
      "77/81 [===========================>..] - ETA: 0s - loss: 1.3361 - accuracy: 0.3916\n",
      "Epoch 23: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3388 - accuracy: 0.3920 - val_loss: 1.6229 - val_accuracy: 0.2725\n",
      "Epoch 24/99\n",
      "76/81 [===========================>..] - ETA: 0s - loss: 1.3370 - accuracy: 0.3898\n",
      "Epoch 24: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3379 - accuracy: 0.3916 - val_loss: 1.4185 - val_accuracy: 0.4015\n",
      "Epoch 25/99\n",
      "77/81 [===========================>..] - ETA: 0s - loss: 1.3346 - accuracy: 0.3916\n",
      "Epoch 25: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3372 - accuracy: 0.3916 - val_loss: 1.3381 - val_accuracy: 0.3878\n",
      "Epoch 26/99\n",
      "74/81 [==========================>...] - ETA: 0s - loss: 1.3372 - accuracy: 0.3906\n",
      "Epoch 26: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3365 - accuracy: 0.3920 - val_loss: 1.3157 - val_accuracy: 0.4015\n",
      "Epoch 27/99\n",
      "74/81 [==========================>...] - ETA: 0s - loss: 1.3366 - accuracy: 0.3932\n",
      "Epoch 27: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3359 - accuracy: 0.3943 - val_loss: 1.3127 - val_accuracy: 0.4060\n",
      "Epoch 28/99\n",
      "72/81 [=========================>....] - ETA: 0s - loss: 1.3384 - accuracy: 0.3911\n",
      "Epoch 28: val_accuracy did not improve from 0.40599\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3353 - accuracy: 0.3947 - val_loss: 1.3550 - val_accuracy: 0.4033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmp77wm34gj\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmp77wm34gj\\assets\n",
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating model k=2, c=0: 'PrefetchDataset' object has no attribute 'rebatch'\n",
      "\n",
      "\n",
      "\n",
      "{'k': 2, 'c': 0, 'max_val_acc': -3}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k_1_c_0\n",
      "\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 1.8257 - accuracy: 0.2005 - val_loss: 1.6183 - val_accuracy: 0.1980\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# ---- Run NAS ----\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting search...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m path_to_tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mcolabNAS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ---- Stop clearing ----\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stop_clear\u001b[38;5;241m.\u001b[39mset()\n",
      "File \u001b[1;32ms:\\TinyML\\Workspace\\local_colabnas.py:296\u001b[0m, in \u001b[0;36mLocalColabNAS.search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m         previous_architecture \u001b[38;5;241m=\u001b[39m current_architecture\n\u001b[0;32m    295\u001b[0m         k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 296\u001b[0m         current_architecture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplore_num_cells\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m resulting_architecture \u001b[38;5;241m=\u001b[39m previous_architecture\n\u001b[0;32m    299\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32ms:\\TinyML\\Workspace\\local_colabnas.py:261\u001b[0m, in \u001b[0;36mLocalColabNAS.explore_num_cells\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m    259\u001b[0m     c \u001b[38;5;241m=\u001b[39m c \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 261\u001b[0m     current_architecture \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcurrent_architecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m previous_architecture\n",
      "File \u001b[1;32ms:\\TinyML\\Workspace\\local_colabnas.py:216\u001b[0m, in \u001b[0;36mLocalColabNAS.evaluate_model_process\u001b[1;34m(self, k, c)\u001b[0m\n\u001b[0;32m    213\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ds, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_ds)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Estimate memory usage\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m Flash, RAM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRAM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRAM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Flash: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFlash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MACC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMACC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Check constraints\u001b[39;00m\n",
      "File \u001b[1;32ms:\\TinyML\\Workspace\\local_colabnas.py:183\u001b[0m, in \u001b[0;36mLocalColabNAS.estimate_memory_usage\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate Flash and RAM usage without STM32 tools\"\"\"\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Get model size (Flash estimation)\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_trained_models\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m flash_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_to_trained_models \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Estimate RAM (simplified calculation)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\engine\\training.py:2698\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave\u001b[39m(\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2652\u001b[0m     save_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2653\u001b[0m ):\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \n\u001b[0;32m   2657\u001b[0m \u001b[38;5;124;03m    Please see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m   2696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2698\u001b[0m     \u001b[43msave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2702\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2703\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2704\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2705\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2706\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\saving\\save.py:161\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_is_graph_network \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    151\u001b[0m         model, sequential\u001b[38;5;241m.\u001b[39mSequential\n\u001b[0;32m    152\u001b[0m     ):\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetting save_format=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or using `save_weights`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    160\u001b[0m         )\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model_to_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_optimizer\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mSharedObjectSavingScope():\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\saving\\hdf5_format.py:126\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    123\u001b[0m         f\u001b[38;5;241m.\u001b[39mattrs[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m    125\u001b[0m model_weights_group \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 126\u001b[0m \u001b[43msave_weights_to_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_weights_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Keras, to avoid breaking TF.js users.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model\u001b[38;5;241m.\u001b[39moptimizer, optimizer_experimental\u001b[38;5;241m.\u001b[39mOptimizer):\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\saving\\hdf5_format.py:755\u001b[0m, in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, model)\u001b[0m\n\u001b[0;32m    753\u001b[0m     g \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(layer\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    754\u001b[0m     weights \u001b[38;5;241m=\u001b[39m _legacy_weights(layer)\n\u001b[1;32m--> 755\u001b[0m     \u001b[43msave_subset_weights_to_hdf5_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_trainable_weights \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39m_non_trainable_weights\n\u001b[0;32m    757\u001b[0m g \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_level_model_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\saving\\hdf5_format.py:723\u001b[0m, in \u001b[0;36msave_subset_weights_to_hdf5_group\u001b[1;34m(f, weights)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave_subset_weights_to_hdf5_group\u001b[39m(f, weights):\n\u001b[0;32m    717\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save top-level weights of a model to a HDF5 group.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;124;03m        f: HDF5 group.\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;124;03m        weights: List of weight variables.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m     weight_values \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m     weight_names \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights]\n\u001b[0;32m    725\u001b[0m     save_attributes_to_hdf5_group(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_names\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight_names)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\backend.py:4240\u001b[0m, in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   4228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \n\u001b[0;32m   4230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   4238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 4240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   4241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\keras\\backend.py:4240\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \n\u001b[0;32m   4230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4237\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   4238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 4240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   4241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Search for optimal architecture\n",
    "# print(\"Starting search...\")\n",
    "# path_to_tflite_model = colabNAS.search()\n",
    "\n",
    "# if path_to_tflite_model:\n",
    "#     print(f\"\\nSearch completed! Model saved at: {path_to_tflite_model}\")\n",
    "# else:\n",
    "#     print(\"\\nNo feasible architecture found.\")\n",
    "\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def clear_output_every(interval=10):\n",
    "    while not stop_clear.is_set():\n",
    "        time.sleep(interval)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "stop_clear = threading.Event()\n",
    "clear_thread = threading.Thread(target=clear_output_every, args=(10,))\n",
    "clear_thread.start()\n",
    "\n",
    "# ---- Run NAS ----\n",
    "print(\"Starting search...\")\n",
    "path_to_tflite_model = colabNAS.search()\n",
    "\n",
    "# ---- Stop clearing ----\n",
    "stop_clear.set()\n",
    "clear_thread.join()\n",
    "\n",
    "# ---- Final message ----\n",
    "clear_output(wait=True)\n",
    "if path_to_tflite_model:\n",
    "    print(f\"Search completed! Model saved at: {path_to_tflite_model}\")\n",
    "else:\n",
    "    print(\"No feasible architecture found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for validation.\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFLite model test accuracy: 0.6080\n",
      "Model size: 7.48 KB\n",
      "Model accuracy: 0.6080\n"
     ]
    }
   ],
   "source": [
    "# Test the model if found\n",
    "if path_to_tflite_model and Path(path_to_tflite_model).exists():\n",
    "    # Create test dataset\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=str(data_dir),\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        image_size=input_shape[0:2],\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        validation_split=0.8,\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    accuracy = test_tflite_model(path_to_tflite_model, test_ds)\n",
    "    \n",
    "    model_size = Path(path_to_tflite_model).stat().st_size\n",
    "    print(f\"Model size: {model_size/1024:.2f} KB\")\n",
    "    print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No model to test.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
