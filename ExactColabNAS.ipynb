{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local ColabNAS - Exact Configuration\n",
    "\n",
    "Using the complete flower dataset with your exact specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from local_colabnas import LocalColabNAS, test_tflite_model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: C:\\Users\\Chakkaphan\\.keras\\datasets\\flower_photos_extracted\\flower_photos\n",
      "Classes found: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# Download and setup dataset - exact as requested\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
    "data_dir = Path(data_dir).with_suffix('')\n",
    "\n",
    "# Fix dataset structure - point to actual flower_photos folder\n",
    "actual_data_dir = data_dir / 'flower_photos'\n",
    "if actual_data_dir.exists():\n",
    "    data_dir = actual_data_dir\n",
    "\n",
    "print(f\"Dataset directory: {data_dir}\")\n",
    "print(f\"Classes found: {[d.name for d in data_dir.iterdir() if d.is_dir()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Input shape: (50, 50, 3)\n",
      "  RAM limit: 40960 bytes\n",
      "  Flash limit: 131072 bytes\n",
      "  MACC limit: 2730000\n"
     ]
    }
   ],
   "source": [
    "# Exact configuration from your request\n",
    "input_shape = (50,50,3)\n",
    "\n",
    "#target: STM32L412KBU3\n",
    "#273 CoreMark, 40 kiB RAM, 128 kiB Flash\n",
    "peak_RAM_upper_bound = 40960\n",
    "Flash_upper_bound = 131072\n",
    "MACC_upper_bound = 2730000 #CoreMark * 1e4\n",
    "\n",
    "path_to_training_set = data_dir\n",
    "val_split = 0.3\n",
    "cache = True\n",
    "save_path = './trained_models/'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Input shape: {input_shape}\")\n",
    "print(f\"  RAM limit: {peak_RAM_upper_bound} bytes\")\n",
    "print(f\"  Flash limit: {Flash_upper_bound} bytes\")\n",
    "print(f\"  MACC limit: {MACC_upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Information:\n",
      "  No GPU detected - using CPU\n",
      "Initializing LocalColabNAS with 5 classes\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2569 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 1101 files for validation.\n",
      "\n",
      "ColabNAS initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# GPU check (equivalent to !nvidia-smi)\n",
    "print(\"GPU Information:\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"  {gpu}\")\n",
    "else:\n",
    "    print(\"  No GPU detected - using CPU\")\n",
    "\n",
    "# Initialize ColabNAS (using LocalColabNAS)\n",
    "colabNAS = LocalColabNAS(\n",
    "    max_RAM=peak_RAM_upper_bound, \n",
    "    max_Flash=Flash_upper_bound, \n",
    "    max_MACC=MACC_upper_bound, \n",
    "    path_to_training_set=str(path_to_training_set), \n",
    "    val_split=val_split, \n",
    "    cache=cache, \n",
    "    input_shape=input_shape, \n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "print(\"\\nColabNAS initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.54587\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6212 - loss: 0.9625 - val_accuracy: 0.5332 - val_loss: 1.2367\n",
      "Epoch 38/99\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6247 - loss: 0.9594\n",
      "Epoch 38: val_accuracy did not improve from 0.54587\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6248 - loss: 0.9591 - val_accuracy: 0.5350 - val_loss: 1.2311\n",
      "Epoch 39/99\n",
      "\u001b[1m77/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6259 - loss: 0.9606\n",
      "Epoch 39: val_accuracy did not improve from 0.54587\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6262 - loss: 0.9589 - val_accuracy: 0.5286 - val_loss: 1.2265\n",
      "Epoch 40/99\n",
      "\u001b[1m77/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6308 - loss: 0.9573\n",
      "Epoch 40: val_accuracy did not improve from 0.54587\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6309 - loss: 0.9556 - val_accuracy: 0.5431 - val_loss: 1.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmpz9d2sc_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmpz9d2sc_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmpz9d2sc_7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float32, name='input_layer_6')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2027295689712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295690592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027277149808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027277150688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027296955728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027277150160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295529792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295530320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295528736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295527328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295528208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295529088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295456064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295455888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027276974208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027276974032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295453776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2027295453248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{'k': 16, 'c': 0, 'RAM': 33812, 'Flash': 68304, 'MACC': 1080281, 'max_val_acc': 0.546}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k_16_c_1\n",
      "\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4034 - loss: 1.4450 - val_accuracy: 0.3751 - val_loss: 1.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAM: 56596, Flash: 152848, MACC: 3961049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'k': 16, 'c': 1, 'RAM': 'Outside the upper bound', 'Flash': 'Outside the upper bound', 'MACC': 'Outside the upper bound', 'max_val_acc': -3}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resulting architecture: {'k': 8, 'c': 1, 'RAM': 37716, 'Flash': 96792, 'MACC': 1260281, 'max_val_acc': 0.599}\n",
      "\n",
      "Model saved to: trained_models\\resulting_architecture_k_8_c_1.tflite\n",
      "Elapsed time (search): 0:01:34.886554\n",
      "\n",
      "Total models evaluated: 7\n",
      "\n",
      "Search completed! Model saved at: trained_models\\resulting_architecture_k_8_c_1.tflite\n"
     ]
    }
   ],
   "source": [
    "# Search for optimal architecture\n",
    "print(\"Starting search...\")\n",
    "path_to_tflite_model = colabNAS.search()\n",
    "\n",
    "if path_to_tflite_model:\n",
    "    print(f\"\\nSearch completed! Model saved at: {path_to_tflite_model}\")\n",
    "else:\n",
    "    print(\"\\nNo feasible architecture found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for validation.\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFLite model test accuracy: 0.6080\n",
      "Model size: 7.48 KB\n",
      "Model accuracy: 0.6080\n"
     ]
    }
   ],
   "source": [
    "# Test the model if found\n",
    "if path_to_tflite_model and Path(path_to_tflite_model).exists():\n",
    "    # Create test dataset\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=str(data_dir),\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        image_size=input_shape[0:2],\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        validation_split=0.8,\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    accuracy = test_tflite_model(path_to_tflite_model, test_ds)\n",
    "    \n",
    "    model_size = Path(path_to_tflite_model).stat().st_size\n",
    "    print(f\"Model size: {model_size/1024:.2f} KB\")\n",
    "    print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No model to test.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
