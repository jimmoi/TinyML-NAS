{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local ColabNAS - Exact Configuration\n",
    "\n",
    "Using the complete flower dataset with your exact specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'local_colabnas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlocal_colabnas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalColabNAS, test_tflite_model\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'local_colabnas'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from local_colabnas import LocalColabNAS, test_tflite_model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "GPU(s) available:\n",
      "   PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU(s) available:\")\n",
    "    for gpu in gpus:\n",
    "        print(\"  \", gpu)\n",
    "else:\n",
    "    print(\"❌ No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dataset_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflower_photos.tar\u001b[39m\u001b[38;5;124m'\u001b[39m, origin\u001b[38;5;241m=\u001b[39mdataset_url, extract\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(data_dir)\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fix dataset structure - point to actual flower_photos folder\u001b[39;00m\n\u001b[0;32m      7\u001b[0m actual_data_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflower_photos\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Download and setup dataset - exact as requested\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
    "data_dir = Path(data_dir).with_suffix('')\n",
    "\n",
    "# Fix dataset structure - point to actual flower_photos folder\n",
    "actual_data_dir = data_dir / 'flower_photos'\n",
    "if actual_data_dir.exists():\n",
    "    data_dir = actual_data_dir\n",
    "\n",
    "print(f\"Dataset directory: {data_dir}\")\n",
    "print(f\"Classes found: {[d.name for d in data_dir.iterdir() if d.is_dir()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Input shape: (50, 50, 3)\n",
      "  RAM limit: 40960 bytes\n",
      "  Flash limit: 131072 bytes\n",
      "  MACC limit: 2730000\n"
     ]
    }
   ],
   "source": [
    "# Exact configuration from your request\n",
    "input_shape = (50,50,3)\n",
    "\n",
    "#target: STM32L412KBU3\n",
    "#273 CoreMark, 40 kiB RAM, 128 kiB Flash\n",
    "peak_RAM_upper_bound = 40960\n",
    "Flash_upper_bound = 131072\n",
    "MACC_upper_bound = 2730000 #CoreMark * 1e4\n",
    "\n",
    "path_to_training_set = data_dir\n",
    "val_split = 0.3\n",
    "cache = True\n",
    "save_path = './trained_models/'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Input shape: {input_shape}\")\n",
    "print(f\"  RAM limit: {peak_RAM_upper_bound} bytes\")\n",
    "print(f\"  Flash limit: {Flash_upper_bound} bytes\")\n",
    "print(f\"  MACC limit: {MACC_upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Information:\n",
      "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LocalColabNAS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  No GPU detected - using CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize ColabNAS (using LocalColabNAS)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m colabNAS \u001b[38;5;241m=\u001b[39m \u001b[43mLocalColabNAS\u001b[49m(\n\u001b[0;32m     11\u001b[0m     max_RAM\u001b[38;5;241m=\u001b[39mpeak_RAM_upper_bound, \n\u001b[0;32m     12\u001b[0m     max_Flash\u001b[38;5;241m=\u001b[39mFlash_upper_bound, \n\u001b[0;32m     13\u001b[0m     max_MACC\u001b[38;5;241m=\u001b[39mMACC_upper_bound, \n\u001b[0;32m     14\u001b[0m     path_to_training_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(path_to_training_set), \n\u001b[0;32m     15\u001b[0m     val_split\u001b[38;5;241m=\u001b[39mval_split, \n\u001b[0;32m     16\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache, \n\u001b[0;32m     17\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39minput_shape, \n\u001b[0;32m     18\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColabNAS initialized successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LocalColabNAS' is not defined"
     ]
    }
   ],
   "source": [
    "# GPU check (equivalent to !nvidia-smi)\n",
    "print(\"GPU Information:\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"  {gpu}\")\n",
    "else:\n",
    "    print(\"  No GPU detected - using CPU\")\n",
    "\n",
    "# Initialize ColabNAS (using LocalColabNAS)\n",
    "colabNAS = LocalColabNAS(\n",
    "    max_RAM=peak_RAM_upper_bound, \n",
    "    max_Flash=Flash_upper_bound, \n",
    "    max_MACC=MACC_upper_bound, \n",
    "    path_to_training_set=str(path_to_training_set), \n",
    "    val_split=val_split, \n",
    "    cache=cache, \n",
    "    input_shape=input_shape, \n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "print(\"\\nColabNAS initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: val_accuracy improved from 0.48501 to 0.50772, saving model to trained_models\\trained_models\\k_16_c_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5146 - loss: 1.1914 - val_accuracy: 0.5077 - val_loss: 1.2634\n",
      "Epoch 5/99\n",
      "\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5325 - loss: 1.1634\n",
      "Epoch 5: val_accuracy improved from 0.50772 to 0.51226, saving model to trained_models\\trained_models\\k_16_c_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5328 - loss: 1.1628 - val_accuracy: 0.5123 - val_loss: 1.2549\n",
      "Epoch 6/99\n",
      "\u001b[1m76/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5472 - loss: 1.1412\n",
      "Epoch 6: val_accuracy improved from 0.51226 to 0.53860, saving model to trained_models\\trained_models\\k_16_c_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5483 - loss: 1.1395 - val_accuracy: 0.5386 - val_loss: 1.1847\n",
      "Epoch 7/99\n",
      "\u001b[1m76/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5632 - loss: 1.1236\n",
      "Epoch 7: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5639 - loss: 1.1217 - val_accuracy: 0.5286 - val_loss: 1.1924\n",
      "Epoch 8/99\n",
      "\u001b[1m78/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5657 - loss: 1.1089\n",
      "Epoch 8: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5662 - loss: 1.1078 - val_accuracy: 0.5295 - val_loss: 1.1777\n",
      "Epoch 9/99\n",
      "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5728 - loss: 1.0934\n",
      "Epoch 9: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5731 - loss: 1.0926 - val_accuracy: 0.5104 - val_loss: 1.2344\n",
      "Epoch 10/99\n",
      "\u001b[1m74/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5744 - loss: 1.0819\n",
      "Epoch 10: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5755 - loss: 1.0796 - val_accuracy: 0.4986 - val_loss: 1.2538\n",
      "Epoch 11/99\n",
      "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5824 - loss: 1.0710\n",
      "Epoch 11: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5827 - loss: 1.0702 - val_accuracy: 0.4750 - val_loss: 1.3043\n",
      "Epoch 12/99\n",
      "\u001b[1m74/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5878 - loss: 1.0637\n",
      "Epoch 12: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5884 - loss: 1.0611 - val_accuracy: 0.4414 - val_loss: 1.3501\n",
      "Epoch 13/99\n",
      "\u001b[1m78/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5888 - loss: 1.0570\n",
      "Epoch 13: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5892 - loss: 1.0557 - val_accuracy: 0.4441 - val_loss: 1.3563\n",
      "Epoch 14/99\n",
      "\u001b[1m79/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5863 - loss: 1.0486\n",
      "Epoch 14: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5868 - loss: 1.0476 - val_accuracy: 0.4133 - val_loss: 1.3942\n",
      "Epoch 15/99\n",
      "\u001b[1m78/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5932 - loss: 1.0422\n",
      "Epoch 15: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5937 - loss: 1.0408 - val_accuracy: 0.3960 - val_loss: 1.4604\n",
      "Epoch 16/99\n",
      "\u001b[1m80/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5861 - loss: 1.0339\n",
      "Epoch 16: val_accuracy did not improve from 0.53860\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5865 - loss: 1.0332 - val_accuracy: 0.3742 - val_loss: 1.5116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmprr8kvff5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmprr8kvff5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\CHAKKA~1\\AppData\\Local\\Temp\\tmprr8kvff5'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 50, 3), dtype=tf.float32, name='input_layer_6')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1328620777312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620827568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620868528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620869584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620830560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620868352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620847696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620847520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620849456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620850160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620848928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620849104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620905744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620905568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620907504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328214519872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620906976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1328620907152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{'k': 16, 'c': 0, 'RAM': 33812, 'Flash': 68304, 'MACC': 1080281, 'max_val_acc': 0.539}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "k_16_c_1\n",
      "\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3945 - loss: 1.4617 - val_accuracy: 0.3824 - val_loss: 1.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAM: 56596, Flash: 152848, MACC: 3961049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'k': 16, 'c': 1, 'RAM': 'Outside the upper bound', 'Flash': 'Outside the upper bound', 'MACC': 'Outside the upper bound', 'max_val_acc': -3}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Resulting architecture: {'k': 8, 'c': 0, 'RAM': 31700, 'Flash': 62040, 'MACC': 540089, 'max_val_acc': 0.598}\n",
      "\n",
      "Model saved to: trained_models\\resulting_architecture_k_8_c_0.tflite\n",
      "Elapsed time (search): 0:02:11.055241\n",
      "\n",
      "Total models evaluated: 7\n",
      "\n",
      "Search completed! Model saved at: trained_models\\resulting_architecture_k_8_c_0.tflite\n"
     ]
    }
   ],
   "source": [
    "# Search for optimal architecture\n",
    "print(\"Starting search...\")\n",
    "path_to_tflite_model = colabNAS.search()\n",
    "\n",
    "if path_to_tflite_model:\n",
    "    print(f\"\\nSearch completed! Model saved at: {path_to_tflite_model}\")\n",
    "else:\n",
    "    print(\"\\nNo feasible architecture found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for validation.\n",
      "Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chakkaphan\\anaconda3\\envs\\tinyml\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TFLite model test accuracy: 0.5930\n",
      "Model size: 4.48 KB\n",
      "Model accuracy: 0.5930\n"
     ]
    }
   ],
   "source": [
    "# Test the model if found\n",
    "if path_to_tflite_model and Path(path_to_tflite_model).exists():\n",
    "    # Create test dataset\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=str(data_dir),\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        image_size=input_shape[0:2],\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        validation_split=0.8,\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    print(\"Testing model...\")\n",
    "    accuracy = test_tflite_model(path_to_tflite_model, test_ds)\n",
    "    \n",
    "    model_size = Path(path_to_tflite_model).stat().st_size\n",
    "    print(f\"Model size: {model_size/1024:.2f} KB\")\n",
    "    print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"No model to test.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
